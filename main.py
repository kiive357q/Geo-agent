#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Geo-Agent Dingo-Phoenix ç»Ÿä¸€å…¥å£
"""

import argparse
import os
import numpy as np
import torch
from dingo_core.engine.trainer import Trainer
from geo_agent.core.brain import GeoBrain
from dingo_core.dataset.dingo_dataset import DingoDataModule

def train(args):
    """
    è®­ç»ƒæ¨¡å‹
    """
    # è®­ç»ƒé…ç½®
    config = {
        'data_dir': args.data_dir,
        'checkpoint_dir': args.checkpoint_dir,
        'batch_size': args.batch_size,
        'max_length': args.max_length,
        'train_val_split': args.train_val_split,
        'epochs': args.epochs,
        'learning_rate': args.learning_rate,
        'weight_decay': args.weight_decay,
        'wave_eq_weight': args.wave_eq_weight
    }
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(config)
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train()

def infer(args):
    """
    æ¨ç†é¢„æµ‹
    """
    # åˆ›å»º Geo Brain
    agent = GeoBrain()
    
    # åŠ è½½æµ‹è¯•æ³¢å½¢æ•°æ®
    if os.path.exists(args.waveform_path):
        # è¯Šæ–­
        report = agent.diagnose(args.waveform_path)
        
        if report['status'] == 'success':
            print("\n=== è¯Šæ–­æŠ¥å‘Š ===")
            print(f"æ¡©é•¿: {report['pile_length']:.1f}m")
            print(f"ç¼ºé™·æ·±åº¦: {report['defect_depth']:.1f}m")
            print(f"ç½®ä¿¡åº¦: {report['confidence']:.4f}")
            print(f"å®Œæ•´æ€§ç­‰çº§: {report['integrity_level']}")
            print(f"æè¿°: {report['description']}")
            print(f"ç»“è®º: {report['conclusion']}")
            print(f"å»ºè®®: {report['recommendation']}")
            print(f"åœ°è´¨ç±»å‹: {report['geo_type']}")
            print("==============\n")
        else:
            print(f"é”™è¯¯: {report['message']}")
        
        # ä¿å­˜æŠ¥å‘Š
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                if report['status'] == 'success':
                    f.write("=== è¯Šæ–­æŠ¥å‘Š ===\n")
                    f.write(f"æ¡©é•¿: {report['pile_length']:.1f}m\n")
                    f.write(f"ç¼ºé™·æ·±åº¦: {report['defect_depth']:.1f}m\n")
                    f.write(f"ç½®ä¿¡åº¦: {report['confidence']:.4f}\n")
                    f.write(f"å®Œæ•´æ€§ç­‰çº§: {report['integrity_level']}\n")
                    f.write(f"æè¿°: {report['description']}\n")
                    f.write(f"ç»“è®º: {report['conclusion']}\n")
                    f.write(f"å»ºè®®: {report['recommendation']}\n")
                    f.write(f"åœ°è´¨ç±»å‹: {report['geo_type']}\n")
                    f.write("==============\n")
                else:
                    f.write(f"é”™è¯¯: {report['message']}\n")
            print(f"Report saved to: {args.output}")
    else:
        print(f"Waveform file not found: {args.waveform_path}")

def test_dataset(args):
    """
    æµ‹è¯•æ•°æ®é›†
    """
    # æµ‹è¯• DataModule
    data_module = DingoDataModule(
        data_dir=args.data_dir,
        batch_size=args.batch_size,
        max_length=args.max_length,
        train_val_split=args.train_val_split
    )
    
    data_module.setup()
    train_loader = data_module.train_dataloader()
    val_loader = data_module.val_dataloader()
    
    print(f"Train loader batches: {len(train_loader)}")
    print(f"Val loader batches: {len(val_loader)}")
    
    # æµ‹è¯•æ•°æ®åŠ è½½å™¨
    if len(train_loader) > 0:
        batch = next(iter(train_loader))
        print(f"Batch wave shape: {batch['wave'].shape}")
        if 'length' in batch:
            print(f"Batch length shape: {batch['length'].shape}")
        if 'dt' in batch:
            print(f"Batch dt shape: {batch['dt'].shape}")
        if 'label' in batch:
            print(f"Batch label shape: {batch['label'].shape}")

def chat(args):
    """
    CLI äº¤äº’æ¨¡å¼
    """
    print("ğŸš€ Geo-Agent å¯¹è¯æ¨¡å¼å¯åŠ¨")
    print("=====================================")
    print("æ¬¢è¿ä½¿ç”¨ Geo-Agentï¼æˆ‘æ˜¯ä¸€ä¸ªå…·å¤‡ RAG å’Œ CoT èƒ½åŠ›çš„å¯¹è¯å¼ Agentã€‚")
    print("æˆ‘å¯ä»¥å¸®åŠ©æ‚¨åˆ†ææ¡©èº«å®Œæ•´æ€§ï¼Œæ£€æµ‹å¯èƒ½çš„ç¼ºé™·ã€‚")
    print("è¯·è¾“å…¥æ³¢å½¢æ–‡ä»¶è·¯å¾„ï¼Œæˆ–è¾“å…¥ 'exit' é€€å‡ºã€‚")
    print("=====================================")
    
    # åˆ›å»º Geo Brain
    try:
        agent = GeoBrain()
        print(f"âœ… ç³»ç»Ÿå°±ç»ª: {agent.get_system_info()['model']}")
        print(f"âœ… è§„åˆ™å¼•æ“: {agent.get_system_info()['rules']}")
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # äº¤äº’å¾ªç¯
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            file_path = input("\nè¯·è¾“å…¥æ³¢å½¢æ–‡ä»¶è·¯å¾„: ").strip()
            
            # æ£€æŸ¥æ˜¯å¦é€€å‡º
            if file_path.lower() == 'exit':
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                continue
            
            # è¯Šæ–­
            report = agent.diagnose(file_path)
            
            if report['status'] == 'success':
                print("\n=== è¯Šæ–­æŠ¥å‘Š ===")
                print(f"æ¡©é•¿: {report['pile_length']:.1f}m")
                print(f"ç¼ºé™·æ·±åº¦: {report['defect_depth']:.1f}m")
                print(f"ç½®ä¿¡åº¦: {report['confidence']:.4f}")
                print(f"å®Œæ•´æ€§ç­‰çº§: {report['integrity_level']}")
                print(f"æè¿°: {report['description']}")
                print(f"ç»“è®º: {report['conclusion']}")
                print(f"å»ºè®®: {report['recommendation']}")
                print(f"åœ°è´¨ç±»å‹: {report['geo_type']}")
                print("==============")
            else:
                print(f"âŒ è¯Šæ–­å¤±è´¥: {report['message']}")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
            continue

def main():
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(description='Geo-Agent Dingo-Phoenix')
    
    # å­å‘½ä»¤
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # è®­ç»ƒå‘½ä»¤
    train_parser = subparsers.add_parser('train', help='Train the model')
    train_parser.add_argument('--data_dir', type=str, required=True, help='Data directory')
    train_parser.add_argument('--checkpoint_dir', type=str, default='checkpoints', help='Checkpoint directory')
    train_parser.add_argument('--batch_size', type=int, default=32, help='Batch size')
    train_parser.add_argument('--max_length', type=int, default=1024, help='Max waveform length')
    train_parser.add_argument('--train_val_split', type=float, default=0.8, help='Train/val split ratio')
    train_parser.add_argument('--epochs', type=int, default=100, help='Number of epochs')
    train_parser.add_argument('--learning_rate', type=float, default=1e-4, help='Learning rate')
    train_parser.add_argument('--weight_decay', type=float, default=1e-5, help='Weight decay')
    train_parser.add_argument('--wave_eq_weight', type=float, default=0.1, help='Wave equation loss weight')
    
    # æ¨ç†å‘½ä»¤
    infer_parser = subparsers.add_parser('infer', help='Inference with the model')
    infer_parser.add_argument('--waveform_path', type=str, required=True, help='Waveform file path')
    infer_parser.add_argument('--output', type=str, help='Output report path')
    
    # å¯¹è¯æ¨¡å¼å‘½ä»¤
    chat_parser = subparsers.add_parser('chat', help='CLI interactive mode')
    
    # æµ‹è¯•æ•°æ®é›†å‘½ä»¤
    test_parser = subparsers.add_parser('test_dataset', help='Test the dataset')
    test_parser.add_argument('--data_dir', type=str, required=True, help='Data directory')
    test_parser.add_argument('--batch_size', type=int, default=8, help='Batch size')
    test_parser.add_argument('--max_length', type=int, default=1024, help='Max waveform length')
    test_parser.add_argument('--train_val_split', type=float, default=0.8, help='Train/val split ratio')
    
    # è§£æå‚æ•°
    args = parser.parse_args()
    
    # æ‰§è¡Œå‘½ä»¤
    if args.command == 'train':
        train(args)
    elif args.command == 'infer':
        infer(args)
    elif args.command == 'chat':
        chat(args)
    elif args.command == 'test_dataset':
        test_dataset(args)
    else:
        parser.print_help()

if __name__ == '__main__':
    main()
